\section{Experiment Results}

In this section, we would describe the datasets that we used to perform our experiments. For starting our experiments we have used two different datasets, simulated and real-world data. The simulated data is enable to evaluate the detection performance of our system and compare with DECANTeR \cite{bortolameotti2017decanter}.


\subsection{Experimental Settings}

\begin{table*}[!h]
\centering
\caption{Overview of the Datasets. We collect five datasets which industry series sets were real-world flows and the remaining of three were simulated data. Since the real-world traffic cannot be properly labeled, we treat real-world data as benign traffic. These data are captured by tcpdump and then using the scapy module to extract the HTTP header information we need.}
\label{tbl:db_02}
\begin{tabular}{|c|c|c|c|c|c|}
\hline\hline
Dataset         & Features & Types            & All Samples & Benign Samples & Malicious Samples \\ \hline
Industy\_flow01 & Packets  & Traffic Flows & 1,690,869   & 1,690,869  & N/A               \\ \hline
Industy\_flow02 & Packets  & Traffic Flows & 68,234   & 68,234   & N/A               \\ \hline
Dataset\_01     & Packets  & Botnet          & 1,444    & 1,094     & 350               \\ \hline
Dataset\_02     & Packets  & Botnet          & 1,342    & 1,102     & 240               \\ \hline
Dataset\_03     & Packets  & Botnet          & 1,045   &  877      & 168               \\ \hline\hline
\end{tabular}
\end{table*}


In the following, we briefly present the datasets we used for evaluation in our system. The dataset information is represented in table~\ref{tbl:db_02}.

\begin{itemize}

\item {\bf Real-world Data}

The outbound HTTP traffics we collect from more than hundreds of machines in a technology industry. Users of these machines include accountants, engineers, sales executive, and administrative personnel. Since the users vary from different occupations that lets data become various and complexity. The real world dataset has split into two sets, one is training and the other is testing. Training set has covered first few days and testing set is the traffics of last days. In training set, Industy flow\_01 contains 1,690,869 HTTP requests. and the testing set Industy flow\_02 contains 68,234 HTTP requests in this real-world dataset.

\item {\bf Simulated Data}

In this paper, our goal is a detection of counterfeit fingerprint which would pretend to be browser activities in outbound HTTP traffics. However, this kind of attack is secret and hidden penetration, and hard to collect in the real world. Therefore, we build a botnet malware and monitor its outbound HTTP traffics. As we know, early botnets generally used Internet Relay Chat (IRC) channel to communicate C\&C server. In recent years, botnets also start to communicate C\&C server through HTTP protocol. Furthermore, we need to build a botnet with the spoofing headers which can evade other detection systems. That is why we collect three different simulated botnet traffics. In Dataset\_01, it has no spoofing headers from infected host's outbound HTTP traffics. Dataset\_02 consists of the botnet traffics with simple spoofing, and which means our botnet sending the requests to web-like user agent through HTTP protocol. Finally, Dataset\_03 is totally modifying the headers information, and the malware investigates which browser is used by the user or host, and fills the field User-Agent with that specific browser. Moreover, it also fills up some common requests header fields, like Accept, Accept-Encoding, Accept-Language, and Referrer.

\end{itemize}

\subsection{Evaluation Metrics}

Essentially, Our system is a flow filter aim to identify the suspicious requests with the headers field. Four well-known metrics for evaluating the effectiveness of proposed method are adopted as followings: ``true positive''($TP$) means the number of normal requests which belong to normal traffic. ``False negative''($FN$) is the number of normal traffic and its results are wrongly predicted. Similarly, ``true negative''($TN$) means the number of abnormal traffic and the system predict it as malicious requests, while ``false positive''($FP$) is the number of abnormal traffic that the system predicts it as normal traffic. Based on the accumulation of $TP, FN, TN$, and $FP$, one extended metrics ($accuracy$) popularly used in machine learning problems are also adopted here to evaluate proposed method and listed in equations below. Note that the optimal $accuracy$ of $1.0$ means all of the malware are successfully picked out by the proposed approach. 


\begin{eqnarray}
\label{eq:accuracy}
Accuracy = \frac{TP+TN}{TP+TN+FP+FN}
\end{eqnarray}

\subsection{Effectiveness Analysis}

\begin{table*}[!h]
\centering
\caption{Overview of Evaluation.
For testing the robustness, we add the real-world traffic into each simulated data. We compare the performance of our system and DECANTeR\cite{bortolameotti2017decanter} against different data sets. The accuracy is calculated by equation (\ref{eq:accuracy}) and the detail result will show below.}
\label{tbl:db_03}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline\hline
\multirow{2}{*}{Dataset}                     & \multirow{2}{*}{System} & \multirow{2}{*}{HTTP Requests} & \multicolumn{4}{c|}{Evaluation Metrics} & \multirow{2}{*}{Accuracy} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Counterfeit Fingerprint\\ Detection Rate\end{tabular}} \\ \cline{4-7}
                                             &                         &                                & TP         & TN      & FP      & FN     &                           &                                                                                                   \\ \hline
\multirow{2}{*}{Dataset\_01+Industy\_flow02} & DECANTeR \cite{bortolameotti2017decanter}                & \multirow{2}{*}{69,678}        & 69,328     & 350     & 0       & 0      & 1.0000                    & N/A                                                                                               \\ \cline{2-2} \cline{4-9} 
                                             & Our System              &                                & 69,328     & 350     & 0       & 0      & 1.0000                    & N/A                                                                                               \\ \hline
\multirow{2}{*}{Dataset\_02+Industy\_flow02} & DECANTeR  \cite{bortolameotti2017decanter}               & \multirow{2}{*}{69,576}        & 69,336     & 240     & 0       & 0      & 1.0000                    & N/A                                                                                               \\ \cline{2-2} \cline{4-9} 
                                             & Our System              &                                & 69,336     & 240     & 0       & 0      & 1.0000                    & N/A                                                                                               \\ \hline
\multirow{2}{*}{Dataset\_03+Industy\_flow02} & DECANTeR   \cite{bortolameotti2017decanter}              & \multirow{2}{*}{69,279}        & 69,109     & 0       & 168     & 2      & 0.9975                    & 0\%                                                                                               \\ \cline{2-2} \cline{4-9} 
                                             & Our System              &                                & 69,109     & 168     & 0       & 2      & 0.9999                    & 100\%                                                                                             \\ \hline\hline
\end{tabular}
\end{table*}



Just as we know, malware can easily modify the HTTP header, therefore, we build three kind of malware to evaluate our approach. With these botnets, they all have the same purpose, and which would steal some sensitive information (such as OS information, system account, and the password) and send requests to the C\&C server periodically waiting for commands to execute. The difference between them is the degree of the spoofing HTTP headers. The botnet in Dataset\_01 doesn't spoof any HTTP headers, and we fill up with the empty to the User-Agent field. The botnet in datset\_02 only simply sets the User-agent as a common browser which calls Internet Explore (IE). In the Dataset\_03 , botnet would specifically detect the victim's browser version and system language, and then fill them into the HTTP header. In addition, for the reference field in a HTTP header that we point to the default website. For testing system's robustness, we merge dataset Inudstry\_flow 02 to each simulated data. It may greatly increase the complexity of the detection task. The result is shown in table~\ref{tbl:db_03}, we can see that our system and DECANTeR \cite{bortolameotti2017decanter} both have the great performance with Dataset\_01 and Dataset\_02. However, we can notice that our system has a better performance for botnets in Dataset\_03 based on advanced spoofing methods. When we calculate the distance of two referrer correlation graphs respectively generated in the training and testing dataset, and then using a method to discover the traffics that have suspected counterfeit HTTP header fields. For the distance, we will give a threshold that affects the false positive rate and the detection rate of counterfeit HTTP header, and the setting of threshold is fixed as "10" in our experiments.

In the training stage, We build each fingerprint through the clean data for both systems. For with no User-Agent request headers, which filled in '-' in User-Agent field, we will use the domain and IP to create the fingerprints. Moreover, this concept is just like the idea of the whitelist, and malware can't evade our system detection through the settings of HTTP header with empty User-Agent. The result shows that two detection systems both got an excellent performance in the Dataset\_01. Some malware would use a web-like User-Agent to camouflage themselves as a browser to avoid the system detection. In Dataset\_02, the malware would modify the HTTP header field User-Agent to IE, and disguise itself as a browser and communicate with C\&C server. For this validation set, both systems also got a good score when a malware disguises itself as a browser, and our system would firstly check the request whether whitelist has this fingerprint or not. If yes, the system will compare the difference with these fingerprints. So, unless the malware can guess or use some advanced technology to get the browser information and the language of the OS system used by the victim, and then using this information to forge the HTTP header fields. Otherwise, it is not easy to avoid the first stage of our detection system.

For advanced spoofing methods, the malware can detect the victim's system information such as browser version and system language, and then malware would modify the HTTP header fields when sending requests to C\&C server. For this reason, it is not robust with only the first phase of detection (e.g., DECANTeR \cite{bortolameotti2017decanter}, DUMONT \cite{schwenk2011adaptive}, and WebTap \cite{borders2004web}). Therefore, in addition to creating the fingerprints, we also established the referrer correlation graph during the training phase. For the traffic with the labeling as normal through the first phase by the detection system, and we can carry out the second phase of detection, the detection system would compare the graph edit distance between each referrer correlation graphs. The idea of this detection stems from the fact that we think when humans are browsing the websites, they would click the hyperlink to where they want to browse, and these referrers of the requests can be generated as a referrer correlation path. On the other hand, malware that disguised as a browser cannot link out such a path. We apply this concept to use GED to calculate the difference between these referrer correlation graphs. The results show that our approach is better than DECANTeR \cite{bortolameotti2017decanter}, and it could detect the malware sending requests in Dataset\_03 which using advanced spoofing methods to evading detection system.

\subsection{Limitation and Future Work}

There are two main problems in our approach, however, they are infrequent in practice. First problem is the duration of model training or fingerprint constructing that need a non-compromised environment. Because, our approach is an extension of DECANTeR \cite{bortolameotti2017decanter}, and which needs to generate an application's fingerprint for anomaly detection in a clean environment. Therefore, we also have to perform our approach at the same scenario for benign fingerprint and correlation model construction. The second problematic situation may happen (e.g., TLS) that is due to a lack of browser referrer contents, and this situation may difficultly construct a referrer correlation graph. Moreover, we couldn't extract any information from an encrypted PCAP file when it was encapsulated in TLS unless we use a TLS proxy for traffic decryption. Fortunately, this could be resolved by a tool (e.g., Burp Suite) for interception of TLS requests. 

In the further work, the counterfeit fingerprint not only appears in browser network activities but also usually used in background application for evading detections, and which is breifly described in DECANTeR \cite{bortolameotti2017decanter}. Therefore, we will resolve counterfeit fingerprint in each background application based on the same idea concept with this paper in the future.
